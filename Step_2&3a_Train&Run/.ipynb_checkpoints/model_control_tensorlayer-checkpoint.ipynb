{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRider 自动驾驶车——模型生成与在线运行程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorRider的训练过程除了Google TensorFlow以外，还依赖以下Python程序库:\n",
    "* tensorlayer\n",
    "* matplotlib （可选，用于可视化数据）\n",
    "\n",
    "这些程序库都可以使用pip直接安装。如果出现找不到程序库的错误，请先安装这些程序库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下Cell将会启动一个交互式Tensorflow会话（Session），后面的步骤将依赖```sess```这个Session。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个```preprocess```方法，用于图像预处理。具体功能是将图像中的每个像素红、绿、蓝分量的亮度值域从0-255变换为0-1。\n",
    "\n",
    "当前程序使用彩色图像训练。如果希望尝试使用灰度图像，可以取消方法中的注释，并将```pd=rgb * (1. / 255) #- 0.5```一行注释。这样方法返回的即为灰度图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(rgb):\n",
    "#     r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "#     pd = 0.4 * r + 0.4 * g + 0.2 * b\n",
    "#     pd = pd * (1. / 255)\n",
    "    pd=rgb * (1. / 255)\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义```prepareDataArrays```方法，功能是将TFRecords数据集读入变量中，供直接使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataArrays(iterator):\n",
    "    X = np.empty((0, 14400))\n",
    "    y = np.empty((0,1))\n",
    "    X_buffer = np.empty((0, 14400))\n",
    "    y_buffer = np.empty((0,1))\n",
    "    \n",
    "    recordCounter = 0;\n",
    "\n",
    "    for string_record in iterator:\n",
    "        recordCounter += 1\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(string_record)\n",
    "        imageString = (example.features.feature['image'].bytes_list.value[0])\n",
    "        label = (example.features.feature['label'].int64_list.value[0])\n",
    "        \n",
    "        image = np.fromstring(imageString, dtype=np.uint8)\n",
    "        image = image.reshape((60, 80, 3))\n",
    "        image = preprocess(image)\n",
    "        image = image.reshape((14400))\n",
    "\n",
    "        X_buffer = np.append(X_buffer, [image], axis=0)\n",
    "        y_buffer = np.append(y_buffer, label)\n",
    "        \n",
    "        if recordCounter % 100 == 0:\n",
    "            print(recordCounter,end = '->')\n",
    "        if recordCounter % 1000 == 0:\n",
    "            print(\"Merging\")\n",
    "            X = np.append(X, [X_buffer])\n",
    "            y = np.append(y, [y_buffer])\n",
    "            X_buffer = np.empty((0, 14400))\n",
    "            y_buffer = np.empty((0,1))\n",
    "    \n",
    "    print(\"Done\")        \n",
    "    X = np.append(X, [X_buffer])\n",
    "    y = np.append(y, y_buffer)\n",
    "    \n",
    "    X = X.reshape((recordCounter, 14400))\n",
    "    y = y.reshape((recordCounter,))\n",
    "    y = np.round(y / 6)\n",
    "    y = y + 7\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIterator = tf.python_io.tf_record_iterator(path=\"train.tfrecords\")\n",
    "valIterator = tf.python_io.tf_record_iterator(path=\"val.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecords -> 数组\n",
    "执行读入数据集的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTrain...\")\n",
    "X_train, y_train = prepareDataArrays(trainIterator)\n",
    "print(\"\\nVal...\")\n",
    "X_val, y_val = prepareDataArrays(valIterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [可选步骤] 数组 <-> Numpy数据文件（NPZ）\n",
    "PS：事实上刚才将数据集读入内存的操作（```TFRecords -> 数组```），不是一个很好的加载数据集的方法，因为需要消耗很长时间（我已使用了一些技巧减少需要的时间），并且持续占用计算机的内存（RAM）。\n",
    "\n",
    "一种更好的方法可以令TensorFlow在训练过程中按需载入TFRecords二进制文件，减少对计算机内存（RAM）的占用。\n",
    "\n",
    "因为我们的训练过程使用的数据集规模不是非常大，而且一次载入完整数据集可便于进行一些统计分析，我保留了这种笨办法。\n",
    "如果你想使用这种方法，又不想在```TFRecords -> 数组```步骤中消耗太多时间，你可以尝试使用以下这个可选步骤。这一步将内存数组保存为Numpy数据文件（实际为一个解压缩过程），你可能会得到一个比TFRecords大的NPZ文件。但下次运行程序时你可以直接读入NPZ文件，这将减少读入数据集需要的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可选步骤：保存NPZ文件\n",
    "np.savez(\"arrays_01color.npz\", xtr = X_train, ytr = y_train, xval = X_val, yval = y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可选步骤：重新载入NPZ文件\n",
    "npRecall = np.load(\"arrays_01color.npz\")\n",
    "X_train = npRecall[\"xtr\"]\n",
    "y_train = npRecall[\"ytr\"]\n",
    "X_val = npRecall[\"xval\"]\n",
    "y_val = npRecall[\"yval\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据读入完成后，可使用numpy或matplotlib提供的工具分析数据。\n",
    "\n",
    "下面这个例子绘制了我使用的训练集的转向角度分布情况。重新运行以下Cell，查看你自己的数据集的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.000e+00, 7.000e+00, 3.000e+00, 3.600e+02, 3.472e+03, 5.902e+03,\n",
       "        1.929e+03, 8.452e+03, 1.655e+03, 5.032e+03, 2.718e+03, 4.330e+02,\n",
       "        2.100e+01, 1.000e+01]),\n",
       " array([ 0.        ,  0.92857143,  1.85714286,  2.78571429,  3.71428571,\n",
       "         4.64285714,  5.57142857,  6.5       ,  7.42857143,  8.35714286,\n",
       "         9.28571429, 10.21428571, 11.14285714, 12.07142857, 13.        ]),\n",
       " <a list of 14 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义神经网络\n",
    "以下Cells定义了一个四层BP神经网络模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 14400], name='x')\n",
    "y_ = tf.placeholder(tf.int64, shape=[None], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  input: (?, 14400)\n",
      "[TL] DenseLayer  relu1: 2048 relu\n",
      "[TL] DenseLayer  relu2: 1024 relu\n",
      "[TL] DenseLayer  relu3: 512 relu\n",
      "[TL] DenseLayer  output: 15 No Activation\n"
     ]
    }
   ],
   "source": [
    "network = tl.layers.InputLayer(x, name='input')\n",
    "network = tl.layers.DenseLayer(network, 2048, tf.nn.relu, name='relu1')\n",
    "network = tl.layers.DenseLayer(network, 1024, tf.nn.relu, name='relu2')\n",
    "network = tl.layers.DenseLayer(network, 512, tf.nn.relu, name='relu3')\n",
    "network = tl.layers.DenseLayer(network, n_units=15, act=tf.identity, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = network.outputs\n",
    "cost = tl.cost.cross_entropy(y, y_, name='cost')\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "y_op = tf.argmax(tf.nn.softmax(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = network.all_params\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost, var_list=train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] WARNING: From <ipython-input-7-365805cc28bf>:1: initialize_global_variables (from tensorlayer.layers.utils) is deprecated and will be removed after 2018-09-30.\n",
      "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tl.layers.initialize_global_variables(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL]   param   0: relu1/W:0            (14400, 2048)      float32_ref (mean: -2.9934278700238792e-06, median: -9.142743692791555e-06, std: 0.08796485513448715)   \n",
      "[TL]   param   1: relu1/b:0            (2048,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   2: relu2/W:0            (2048, 1024)       float32_ref (mean: -0.00011276298755547032, median: -0.00015127687947824597, std: 0.08790221065282822)   \n",
      "[TL]   param   3: relu2/b:0            (1024,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   4: relu3/W:0            (1024, 512)        float32_ref (mean: -0.00029735639691352844, median: -0.0003246761334594339, std: 0.08793047070503235)   \n",
      "[TL]   param   5: relu3/b:0            (512,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   6: output/W:0           (512, 15)          float32_ref (mean: 7.813526462996379e-05, median: -0.00045874042552895844, std: 0.08711698651313782)   \n",
      "[TL]   param   7: output/b:0           (15,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   num of params: 32123919\n"
     ]
    }
   ],
   "source": [
    "network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL]   layer   0: x:0                  (?, 14400)         float32\n",
      "[TL]   layer   1: relu1/Relu:0         (?, 2048)          float32\n",
      "[TL]   layer   2: relu2/Relu:0         (?, 1024)          float32\n",
      "[TL]   layer   3: relu3/Relu:0         (?, 512)           float32\n",
      "[TL]   layer   4: output/bias_add:0    (?, 15)            float32\n"
     ]
    }
   ],
   "source": [
    "network.print_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [可选步骤] 设置TensorBoard\n",
    "TensorBoard是TensorFlow提供的一个数据可视化工具。\n",
    "\n",
    "如果你想使用TensorBoard观察训练过程中神经网络的各项参数，可运行以下Cell。\n",
    "\n",
    "如果不使用TensorBoard，不要执行以下Cell，并且在```开始训练```Cell对```tl.utils.fit```方法的调用中将```tensorboard```参数的值改为```False```。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_summ = tf.summary.scalar('acc', acc)\n",
    "cost_summ = tf.summary.scalar('cost', cost)\n",
    "summary = tf.summary.merge_all()  \n",
    "writer = tf.summary.FileWriter('./logs')  \n",
    "writer.add_graph(sess.graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练\n",
    "\n",
    "将```n_epochs```参数设置为希望训练的Epochs数，然后开始训练。若中途发现已训练至收敛，希望停止训练，轻按Jupyter Notebook的停止按钮即可。\n",
    "\n",
    "*运行时需注意计算机的散热情况！*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Setting up tensorboard ...\n",
      "[TL] [!] logs/ exists ...\n",
      "[TL] Param name relu1/W:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name relu1/W:0 is illegal; using relu1/W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Param name relu1/b:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name relu1/b:0 is illegal; using relu1/b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Param name relu2/W:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name relu2/W:0 is illegal; using relu2/W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Param name relu2/b:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name relu2/b:0 is illegal; using relu2/b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Param name relu3/W:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name relu3/W:0 is illegal; using relu3/W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Param name relu3/b:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name relu3/b:0 is illegal; using relu3/b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Param name output/W:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name output/W:0 is illegal; using output/W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Param name output/b:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name output/b:0 is illegal; using output/b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Finished! use $tensorboard --logdir=logs/ to start server\n",
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 500 took 201.655548s\n",
      "[TL]    train loss: 2.255098\n",
      "[TL]    train acc: 0.491318\n",
      "[TL]    val loss: 2.301683\n",
      "[TL]    val acc: 0.477904\n",
      "[TL] Epoch 5 of 500 took 204.699515s\n",
      "[TL]    train loss: 2.662403\n",
      "[TL]    train acc: 0.421594\n",
      "[TL]    val loss: 2.938648\n",
      "[TL]    val acc: 0.410354\n",
      "[TL] Epoch 10 of 500 took 208.691711s\n",
      "[TL]    train loss: 1.272894\n",
      "[TL]    train acc: 0.581456\n",
      "[TL]    val loss: 1.526597\n",
      "[TL]    val acc: 0.503577\n",
      "[TL] Epoch 15 of 500 took 196.837258s\n",
      "[TL]    train loss: 1.228082\n",
      "[TL]    train acc: 0.580920\n",
      "[TL]    val loss: 1.532149\n",
      "[TL]    val acc: 0.542088\n",
      "[TL] Epoch 20 of 500 took 197.391148s\n",
      "[TL]    train loss: 1.039546\n",
      "[TL]    train acc: 0.644476\n",
      "[TL]    val loss: 1.423388\n",
      "[TL]    val acc: 0.582492\n",
      "[TL] Epoch 25 of 500 took 197.517462s\n",
      "[TL]    train loss: 0.904720\n",
      "[TL]    train acc: 0.661270\n",
      "[TL]    val loss: 1.351599\n",
      "[TL]    val acc: 0.541456\n",
      "[TL] Epoch 30 of 500 took 198.242099s\n",
      "[TL]    train loss: 0.907193\n",
      "[TL]    train acc: 0.669818\n",
      "[TL]    val loss: 1.508569\n",
      "[TL]    val acc: 0.537247\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-30785ba700dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m264\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     tensorboard=True, tensorboard_epoch_freq=5, tensorboard_weight_histograms=True, tensorboard_graph_vis=True)\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorlayer\\utils.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(sess, network, train_op, cost, X_train, y_train, x, y_, acc, batch_size, n_epoch, print_freq, X_val, y_val, eval_train, tensorboard, tensorboard_epoch_freq, tensorboard_weight_histograms, tensorboard_graph_vis)\u001b[0m\n\u001b[0;32m    165\u001b[0m                     \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train_a\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                     \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdp_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m                     \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_train_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                     \u001b[0mtensorboard_train_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tl.utils.fit(\n",
    "    sess, network, train_op, cost, X_train, y_train, x, y_, acc=acc, \n",
    "    batch_size=264, n_epoch=40, print_freq=5, X_val=X_val, y_val=y_val, eval_train=True, \n",
    "    tensorboard=True, tensorboard_epoch_freq=5, tensorboard_weight_histograms=True, tensorboard_graph_vis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型以供在线运行\n",
    "\n",
    "保存模型，以供下次在线运行时使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.files.save_npz(network.all_params, name='model_4color.npz')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如需载入保存的模型，请先运行```定义神经网络```部分的Cells，然后运行以下Cell。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.files.load_and_assign_npz(sess=sess, name='model_4color.npz', network=network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型以供离线运行\n",
    "如需离线运行（即在实验小车上连接Intel Movidius NCS神经网络计算棒，不使用计算机作为服务器）\n",
    "\n",
    "请运行以下Cell，将训练好的模型保存为Movidius编译器支持的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "graph_location = \".\"\n",
    "save_path = saver.save(sess, graph_location + \"/tl_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始在线运行\n",
    "启动实验小车，确认网络连接正常，启动小车端的```mjpg-streamer```程序，即可开始在线运行。\n",
    "可在以下Cell中变更小车的IP地址。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import socket\n",
    "import threading\n",
    "from time import ctime,sleep\n",
    "import string\n",
    "from IPython.display import IFrame\n",
    "\n",
    "remoteImage = np.array([])\n",
    "stream = urllib.request.urlopen('http://192.168.73.73:8080/?action=stream&ignored.mjpg')\n",
    "bytes = bytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```kP```为小车的转向比例。如发现转向过度或转向不足，可调整此值。\n",
    "\n",
    "```speed```为在线运行时实验小车的速率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kP = 15\n",
    "speed = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义图像刷新线程和控制线程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Refreshing_Thread():\n",
    "    global remoteImage\n",
    "    global stream\n",
    "    global bytes\n",
    "    while True:\n",
    "        bytes += stream.read(1024)\n",
    "        a = bytes.find(b'\\xff\\xd8')\n",
    "        b = bytes.find(b'\\xff\\xd9')\n",
    "        if a != -1 and b != -1:\n",
    "            jpg = bytes[a:b+2]\n",
    "            bytes = bytes[b+2:]\n",
    "            i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            i = preprocess(i)\n",
    "            remoteImage = i.reshape((1, 14400))\n",
    "\n",
    "def Controlling_Thread():\n",
    "    global remoteImage\n",
    "    addr=('192.168.73.73',51423)\n",
    "    s=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)\n",
    "    while True:\n",
    "        direction = tl.utils.predict(sess, network, remoteImage, x, y_op, batch_size=None)\n",
    "        msgCtrl_Udp = str(speed) + \",\" + str((direction[0] - 7) * kP)\n",
    "        s.sendto(msgCtrl_Udp.encode('utf-8'), addr)\n",
    "        sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预览图像\n",
    "运行此Cell可显示来自小车摄像机的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame('http://192.168.73.73:8080/?action=stream', width=80, height=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分别运行以下Cells，启动图像刷新线程和控制线程。打开电机开关，实验小车将开始运行。\n",
    "\n",
    "运行时仍可调整```kP```与```speed```，调整后运行该Cell，变更将实时生效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefreshImageThread = threading.Thread(target = Image_Refreshing_Thread)\n",
    "RefreshImageThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ControllingThread = threading.Thread(target = Controlling_Thread)\n",
    "ControllingThread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
